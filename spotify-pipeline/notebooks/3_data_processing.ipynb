{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d788725-fd5f-4a98-b04b-19962ce2aa1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Data processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cfdbc8c-cda2-4e69-92d0-718e99bf42f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Data Cleaning Strategy**\n",
    "\n",
    "Deduplication: We remove duplicate rows based on track_id to ensure uniqueness.\n",
    "\n",
    "Missing Values: filling missing text fields (like artists) with \"Unknown\" to maintain data integrity without dropping rows.\n",
    "\n",
    "Outlier Handling: filtering out tracks with unrealistic values (e.g., Tempo < 30 BPM or Duration < 30 seconds) that likely represent data errors or non-musical audio.\n",
    "\n",
    "\n",
    "**Handling uutliers** \n",
    "\n",
    "Rule 1: Tempo must be realistic (greater than 30 BPM)\n",
    "\n",
    "Rule 2: Duration must be meaningful (greater than 30 seconds / 30000ms)\n",
    "\n",
    "Rule 3: Loudness usually shouldn't be positive (in digital audio) - purely a sanity check\n",
    "\n",
    "\n",
    "**Feature Engineering**\n",
    "\n",
    "To prepare the data for analysis and potential Machine Learning, we derive new features:\n",
    "\n",
    "duration_minutes: Converted from milliseconds for better readability.\n",
    "\n",
    "is_explicit_int: Converted boolean explicit column to integer (0/1) for compatibility with ML models.\n",
    "\n",
    "popularity_segment: Grouped tracks into \"Low\", \"Medium\", and \"High\" popularity buckets to simplify categorical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3bc047f-5dc2-4adb-8d1d-d782fde9e0e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, round, lit\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "source_table = \"default.spotify_bronze_partitioned\"\n",
    "target_table_silver = \"default.spotify_silver\"\n",
    "\n",
    "df = spark.read.table(source_table)\n",
    "print(f\"Initial row count: {df.count()}\")\n",
    "\n",
    "\n",
    "# Removing duplicates\n",
    "df_deduped = df.dropDuplicates([\"track_id\"])\n",
    "\n",
    "# Handling missing values\n",
    "df_cleaned = df_deduped.na.fill({\n",
    "    \"artists\": \"Unknown\",\n",
    "    \"album_name\": \"Unknown\",\n",
    "    \"track_name\": \"Untitled\"\n",
    "})\n",
    "\n",
    "print(f\"Row count after deduplication: {df_cleaned.count()}\")\n",
    "\n",
    "df_quality = df_cleaned.filter(\n",
    "    (col(\"tempo\") > 30) & \n",
    "    (col(\"duration_ms\") > 30000)\n",
    ")\n",
    "\n",
    "dropped_count = df_cleaned.count() - df_quality.count()\n",
    "print(f\"Dropped {dropped_count} rows due to outlier/quality checks.\")\n",
    "\n",
    "# Feature Engineering\n",
    "df_enriched = df_quality \\\n",
    "    .withColumn(\"duration_minutes\", round(col(\"duration_ms\") / 60000, 2)) \\\n",
    "    .withColumn(\"is_explicit_int\", col(\"explicit\").cast(\"integer\")) \\\n",
    "    .withColumn(\"popularity_segment\", \n",
    "        when(col(\"popularity\") < 30, \"Low\")\n",
    "        .when(col(\"popularity\") < 70, \"Medium\")\n",
    "        .otherwise(\"High\")\n",
    "    )\n",
    "\n",
    "display(df_enriched.select(\"track_name\", \"duration_minutes\", \"is_explicit_int\", \"popularity_segment\").limit(5))\n",
    "\n",
    "df_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(target_table_silver)\n",
    "\n",
    "print(f\"Transformation complete. Data saved to {target_table_silver}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3_data_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
