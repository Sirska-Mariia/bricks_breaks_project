{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46a6609b-5cc4-4c00-96f1-7d044a1ff786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Data storage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb7ad1c7-fdb6-45dc-a919-810b337a7785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Storage Solution: Databricks Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9b87d01-a006-4eac-a978-9fcc6c33fe06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Justification**\n",
    "\n",
    "Standard CSV or Parquet files are insufficient for a production pipeline. We chose Delta Lake for the following reasons:\n",
    "\n",
    "ACID Transactions: Ensures data integrity. If the pipeline fails midway through a write, we do not end up with partial or corrupt files.\n",
    "\n",
    "Schema Enforcement: Strictly prevents bad data types from polluting the database (e.g., preventing text in the popularity column).\n",
    "\n",
    "Time Travel: Delta automatically versions data, allowing us to query previous snapshots of the table if we accidentally delete rows.\n",
    "\n",
    "Unified Batch & Streaming: The same table can be used for the batch load (current task) and future real-time streaming requirements without architecture changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fb0cbb6-f5af-4b90-99e5-de9e3f1fc94d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Partitioning Strategy**\n",
    "\n",
    "Partition Column: track_genre\n",
    "\n",
    "Reasoning: Downstream analytical queries frequently filter by genre (e.g., \"Compare the energy of Pop vs. Rock tracks\"). By partitioning on track_genre, Databricks can skip reading irrelevant files (Partition Pruning), significantly speeding up these queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf014cc-e2dc-4716-8f62-625635f968ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_table = \"default.spotify_bronze\"\n",
    "target_table_partitioned = \"default.spotify_bronze_partitioned\"\n",
    "\n",
    "#  Implementing data partitioning\n",
    "df = spark.read.table(source_table)\n",
    "\n",
    "print(f\"Writing partitioned data to {target_table_partitioned}...\")\n",
    "\n",
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"track_genre\") \\\n",
    "    .saveAsTable(target_table_partitioned)\n",
    "\n",
    "print(\"Partitioning complete.\")\n",
    "\n",
    "#  Verify storage layout\n",
    "print(\"Verifying partition structure...\")\n",
    "display(spark.sql(f\"DESCRIBE EXTENDED {target_table_partitioned}\"))\n",
    "\n",
    "# Storage optimization\n",
    "spark.sql(f\"OPTIMIZE {target_table_partitioned}\")\n",
    "\n",
    "print(f\"Success: Table {target_table_partitioned} is optimized and partitioned.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_data_storage",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
